{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Project: Galaxy Classifier\n",
    "\n",
    "### Lexy Andershock, Gian Fernandez-Aleman, David Long\n",
    "\n",
    "#### Introduction\n",
    "This course project for our Intro to Machine Learning course (COSC325) utilizes a Stochastic Gradient Descent model, a Random Forest Generator model and a K-Nearest Neighbor model on a dataset of colored galaxy images (Galaxy10 SDSS). While the dataset was originally used with a CNN (a more appropriate model for image data), we wanted to experiment and see what we could do with it using a few of the learning techniques we've learned in class.\n",
    "\n",
    "#### Who is this for?\n",
    "Our target audience for this project would include astronomers, physicists, space enthusiasts, space researchers, educators, and general populations with an interest in galaxy-shape indentification.\n",
    "\n",
    "#### Purpose of the Project\n",
    "The problem we are trying to solve is identifying the shapes of newly discovered galaxies. This dataset contains 10 unique categories of different-shaped galaxies, and we want to train models to be able to assign one of these categories to new images of galaxies it hasn't encountered yet. With new space telescopes such as JWST, we are discovering new galaxies at an accelerating rate, and being able to quickly classify them for studying would be very useful instead of manually doing it. This would make users' lives significantly better as they can have a system that handles massive amounts of galaxy photosets and produces accurate results, which is more time-efficient as opposed to manually determining the galaxy shapes.\n",
    "\n",
    "### 1. Setting Up The Environment\n",
    "We must ensure that we have imported all the appropriate libraries that we will utilize for our data manipulation and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Scikit-learn libraries and routines\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Downloading and Extracting Data + Showing Some Galaxies From Each Label\n",
    "We then download and extract our data from the dataset and organize them into two separate categories: images and labels. One image from each galaxy label is shown for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document how to download + import the dataset\n",
    "url = \"https://zenodo.org/records/10844811/files/Galaxy10.h5\"\n",
    "file_name = \"Galaxy10.h5\"\n",
    "\n",
    "response = requests.get(url, stream=True)\n",
    "if os.path.exists(\"Galaxy10.h5\"):\n",
    "    print(\"File already downloaded.\")\n",
    "else:\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    print(\"Download complete!\")\n",
    "\n",
    "# To get the images and labels from file\n",
    "with h5py.File(file_name, 'r') as data:\n",
    "    images = np.array(data['images'])\n",
    "    labels = np.array(data['ans'])\n",
    "\n",
    "label_names = [\n",
    "        \"Disk, Face-on, No Spiral\",\n",
    "        \"Smooth, Completely round\",\n",
    "        \"Smooth, in-between round\",\n",
    "        \"Smooth, Cigar shaped\",\n",
    "        \"Disk, Edge-on, Rounded Bulge\",\n",
    "        \"Disk, Edge-on, Boxy Bulge\",\n",
    "        \"Disk, Edge-on, No Bulge\",\n",
    "        \"Disk, Face-on, Tight Spiral\",\n",
    "        \"Disk, Face-on, Medium Spiral\",\n",
    "        \"Disk, Face-on, Loose Spiral\"\n",
    "    ]        \n",
    "\n",
    "# Find one sample per unique label\n",
    "unique_classes = np.unique(labels)\n",
    "class_examples = []\n",
    "\n",
    "for class_id in unique_classes:\n",
    "    idx = np.where(labels == class_id)[0][0]\n",
    "    class_examples.append((images[idx], class_id))\n",
    "\n",
    "# Plot in 5 rows of 2\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (img, label) in enumerate(class_examples):\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f\"{label}: {label_names[label]}\", fontsize=9)\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Processing Data\n",
    "We then process our data. In this case, we'll flatten the color images and normalize the pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten images\n",
    "n_samples, height, width, channels = images.shape\n",
    "X = images.reshape(n_samples, height * width * channels)\n",
    "y = labels\n",
    "\n",
    "# Normalize pixel values between 0 and 1\n",
    "X = X.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Distribution in the Data Set (Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Distribution Plot\n",
    "# Get unique class labels and their counts\n",
    "classes, counts = np.unique(y, return_counts=True)\n",
    "percentages = counts / counts.sum() * 100\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(classes, percentages, edgecolor='black')\n",
    "\n",
    "# Add percentage labels on top of each bar\n",
    "for bar, pct in zip(bars, percentages):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height + 0.5,\n",
    "             f'{pct:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.title(\"Sample Distribution per Class\")\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Percentage of Samples\")\n",
    "plt.ylim(0, max(percentages) + 5)  # Add some space above tallest bar\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.xticks(classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Splitting Data\n",
    "Once we have the data put into separate categories, we split it into training and testing categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the full dataset before splitting\n",
    "X, y = shuffle(X, y, random_state = 42)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.9, stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Scaling Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the scaler on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scale = scaler.fit_transform(X_train)\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA after scaling\n",
    "pca = PCA(n_components = 1500)\n",
    "X_train = pca.fit_transform(X_train_scale)\n",
    "X_test = pca.transform(X_test_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Before and After PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize BEFORE PCA (reduce to 2D just for plotting)\n",
    "pca_vis = PCA(n_components=2)\n",
    "X_train_vis_before = pca_vis.fit_transform(scaler.inverse_transform(X_train_scale))  # approximate original\n",
    "\n",
    "plt.plot(1, 2, 1)\n",
    "scatter = plt.scatter(X_train_vis_before[:, 0], X_train_vis_before[:, 1], c=y_train, cmap='tab10', alpha=0.6)\n",
    "plt.title(\"Before PCA\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize AFTER PCA\n",
    "X_train_vis_after = PCA(n_components=2).fit_transform(X_train)\n",
    "\n",
    "plt.plot(1, 2, 2)\n",
    "scatter = plt.scatter(X_train_vis_after[:, 0], X_train_vis_after[:, 1], c=y_train, cmap='tab10', alpha=0.6)\n",
    "plt.title(\"After PCA\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Training The Model!\n",
    "We'll start training the Stochastic Gradient Descent regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using Stochastic Gradient Descent\n",
    "model = OneVsRestClassifier(SGDClassifier(loss = 'log_loss', max_iter = 5000))\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Predicting Using The Model\n",
    "We'll predict on the test set using the model we just trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy : {accuracy:.2f}\\n\")\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division = 0))\n",
    "\n",
    "cm_test = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "\n",
    "#Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized)\n",
    "disp.plot(cmap='Blues', values_format=\".2f\")\n",
    "plt.title(\"Confusion Matrix of SGD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset model for learning curve\n",
    "model = OneVsRestClassifier(SGDClassifier(loss='log_loss', max_iter=300))\n",
    "\n",
    "# Set up learning curve\n",
    "train_sizes = np.linspace(0.1, 1.0, 5)  # only 3 points\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model, X, y,\n",
    "    train_sizes=train_sizes,\n",
    "    cv=2,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, label=\"Training Score\", marker='o')\n",
    "plt.plot(train_sizes, test_mean, label=\"Validation Score\", marker='s')\n",
    "plt.title(\"Learning Curve for Stochastic Gradient Descent\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Model #2: Random Forest\n",
    "For our second model, we decided to use a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified K-Fold RF Model\n",
    "To combat overfitting, we used a stratified K-Fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-Fold Data\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# initialize model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "# k-stratified data\n",
    "skf = StratifiedKFold(n_splits = 10, random_state=42, shuffle=True)\n",
    "\n",
    "# adjust X and y\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)\n",
    "y = y[0]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train = X.iloc[train_index, :]\n",
    "    X_test = X.iloc[test_index, :]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # evaluate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    print(f'Fold Accuracy: {accuracy}')\n",
    "\n",
    "print(f'\\nAverage Accuracy: {sum(accuracy_scores) / len(accuracy_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve for kfold (15 minutes)\n",
    "y = pd.Series(y)  # Convert y to a Series instead of DataFrame\n",
    "\n",
    "# Get learning curve data\n",
    "train_sizes_k, train_scores_k, test_scores_k = learning_curve(\n",
    "    rf_model, X, y,\n",
    "    cv=skf,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5)\n",
    ")\n",
    "\n",
    "# Calculate mean and std\n",
    "train_scores_mean_k = train_scores_k.mean(axis=1)\n",
    "train_scores_std_k = train_scores_k.std(axis=1)\n",
    "test_scores_mean_k = test_scores_k.mean(axis=1)\n",
    "test_scores_std_k = test_scores_k.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Random Forest\n",
    "This is how our random forest model performed with no overfitting mitigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 100 Trees, 80-20 Test-Train Split, Max Depth = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Mititgated Data\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, max_depth = 10)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=rf_model.classes_)\n",
    "disp.plot(cmap=\"Blues\", values_format=\".2f\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curve for non-mitigated data\n",
    "train_sizes, train_scores, test_scores = learning_curve(rf_model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Mean and std deviation\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, label=\"Training Score\", marker='o')\n",
    "plt.plot(train_sizes, test_mean, label=\"Validation Score\", marker='s')\n",
    "plt.plot(train_sizes_k, train_scores_mean_k, label=\"Training Score for SKF\", marker='o')\n",
    "plt.plot(train_sizes_k, test_scores_mean_k, label=\"Validation Score for SKF\", marker='s')\n",
    "plt.title(\"Learning Curve of RF Model\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 30 Trees, 90-10 Test-Train Split, No Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9, stratify=y, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=rf_model.classes_)\n",
    "disp.plot(cmap=\"Blues\", values_format=\".2f\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Learning Curve for non-mitigated data\n",
    "train_sizes_30, train_scores_30, test_scores_30 = learning_curve(rf_model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Mean and std deviation\n",
    "train_mean_30 = np.mean(train_scores_30, axis=1)\n",
    "test_mean_30 = np.mean(test_scores_30, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes_30, train_mean_30, label=\"Training Score\", marker='o')\n",
    "plt.plot(train_sizes_30, test_mean_30, label=\"Validation Score\", marker='s')\n",
    "plt.title(\"Learning Curve of 30-Tree RF Model (No Max Depth)\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning of Random Forest Model\n",
    "This function shows what the hyperparameters should be set to for the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try classification of data (25 minutes).\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Step 1: Split into training + testing (we'll do CV on training only)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Define model and parameter grid\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [20, 30, 70],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Step 3: GridSearch with Cross-Validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                    # 5-fold cross-validation\n",
    "    scoring='accuracy',     # or 'f1', 'roc_auc', etc.\n",
    "    n_jobs=-1,               # Use all processors\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Best model and parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Step 5: Evaluate on test data\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Model #3: K-Nearest Neighbors\n",
    "For our third model, we decided to use K-Nearest Neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "# Fit to data\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred)\n",
    "print(f\"KNN Model Accuracy: {accuracy_knn:.2f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division = 0))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=knn_model.classes_)\n",
    "disp.plot(cmap=\"Blues\", values_format=\".2f\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(knn_model, X, y, cv=3, scoring='accuracy', train_sizes=np.linspace(0.1, 1.0, 5))\n",
    "\n",
    "# Mean and std deviation\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, label=\"Training Score\", marker='o')\n",
    "plt.plot(train_sizes, test_mean, label=\"Validation Score\", marker='s')\n",
    "plt.title(\"Learning Curve of KNN Model\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Analyzing Color and Image Resolution\n",
    "We ran tests to see how image scaling and removing color affects model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.transform import resize\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# function that resizes and converts images to grayscale (if color == false)\n",
    "def preprocess_images(images, color = True, size = (69, 69)):\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        if not color:\n",
    "            # convert to grayscale by averaging the red and green bands\n",
    "            gray = 0.5 * img[..., 0] + 0.5 * img[..., 1]\n",
    "            # resize image to size\n",
    "            img = resize(gray, size, anti_aliasing = True)\n",
    "        else:\n",
    "            # resize image to size with 3 color bands\n",
    "            img = resize(img, (*size, 3), anti_aliasing = True)\n",
    "\n",
    "        processed_images.append(img)\n",
    "    \n",
    "    return np.array(processed_images)\n",
    "\n",
    "# function that flattens images into 1D vectors\n",
    "def flatten_images(images):\n",
    "    return images.reshape((images.shape[0], -1))\n",
    "\n",
    "# defines the different expirements that will be run\n",
    "settings = [\n",
    "    (\"Color 69x69\", True, (69, 69)),\n",
    "    (\"Grayscale 69x69\", False, (69, 69)),\n",
    "    (\"Color 23x23\", True, (23, 23)),\n",
    "    (\"Grayscale 23x23\", False, (23, 23))\n",
    "]\n",
    "\n",
    "# list that stores results for each experiment\n",
    "results = []\n",
    "\n",
    "# iterates over each experiment\n",
    "for title, is_color, shape in settings:\n",
    "    print(f\"\\n===========================\")\n",
    "    print(f\"Running: {title}\")\n",
    "    print(f\"===========================\")\n",
    "\n",
    "    # preprocess images\n",
    "    processed_imgs = preprocess_images(images, color = is_color, size = shape)\n",
    "\n",
    "    # normalize pixel values between 0 and 1\n",
    "    processed_imgs = processed_imgs / 255.0\n",
    "\n",
    "    # flattens images\n",
    "    flattened_imgs = flatten_images(processed_imgs)\n",
    "\n",
    "    # standardizes features\n",
    "    scaler = StandardScaler()\n",
    "    flattened_imgs = scaler.fit_transform(flattened_imgs)\n",
    "\n",
    "    # splits dataset into training and testing sets (80/20)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(flattened_imgs, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "    # trains a random forest model and keeps track of time\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    start_time = time.time()\n",
    "    rf.fit(X_train, y_train)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # trains a random forest model\n",
    "    y_pred = rf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    macro_precision = report['macro avg']['precision']\n",
    "    macro_recall = report['macro avg']['recall']\n",
    "    macro_f1 = report['macro avg']['f1-score']\n",
    "\n",
    "    # prints performance metrics for experiment\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "    print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "    print(f\"Macro F1-Score: {macro_f1:.4f}\")\n",
    "    print(f\"Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # appends the results to the list\n",
    "    results.append({\n",
    "        'Experiment': title,\n",
    "        'Accuracy': acc,\n",
    "        'Macro Precision': macro_precision,\n",
    "        'Macro Recall': macro_recall,\n",
    "        'Macro F1-Score': macro_f1,\n",
    "        'Training Time (s)': elapsed_time\n",
    "    })\n",
    "\n",
    "# creates a DataFrame to summarize all results and display them\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "# Ensure the experiments are in a consistent order\n",
    "results_df = results_df.sort_values(by='Experiment')\n",
    "\n",
    "# Choose metrics to plot\n",
    "metrics = ['Accuracy', 'Macro Precision', 'Macro Recall', 'Macro F1-Score']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.plot(results_df['Experiment'], results_df[metric], marker='o', label=metric)\n",
    "\n",
    "plt.title(\"Model Performance Across Different Image Settings\")\n",
    "plt.xlabel(\"Experiment Setting\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
